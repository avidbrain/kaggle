{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9261e24c",
   "metadata": {},
   "source": [
    "# Tutors - expected math exam results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e25410",
   "metadata": {},
   "source": [
    "Соревнование Kaggle https://www.kaggle.com/c/tutors-expected-math-exam-results\n",
    "\n",
    "Участник: Aleksandr Mikhailov, https://www.kaggle.com/avidclam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81a33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%precision 4\n",
    "import numpy as np\n",
    "np.seterr(over = 'raise')\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea5432",
   "metadata": {},
   "source": [
    "## Примечания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848c2eb",
   "metadata": {},
   "source": [
    "В данной работе хотелось:\n",
    "- реализовать что-либо небанальное;\n",
    "- получить приличный результат.\n",
    "\n",
    "Не хотелось:\n",
    "- переписывать код \"из учебника\".\n",
    "\n",
    "В итоге за основу взято решающее дерево, у которого в узлах находятся модели линейной регрессии. Этот регрессор обеспечивает кусочно-линейную аппроксимацию данных. В качестве критерия деления узла выбрано улучшение коэффициента детерминации R2. Некоторые другие идеи не смогли показать должного результата (либо я не преуспел в их реализации)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b69a8",
   "metadata": {},
   "source": [
    "## Библиотека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a3e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 Score, обрезанный в нуле, т.е. ∈ [0,1]\n",
    "def quality_score(y_true, y_pred):\n",
    "    deviation = y_true - np.mean(y_true)\n",
    "    residuals = y_pred - y_true\n",
    "    dev_square = deviation @ deviation\n",
    "    if np.isclose(dev_square, 0.0):\n",
    "        score = 0.0\n",
    "    else:\n",
    "        score = max(1.0 - (residuals @ residuals) / dev_square, 0.0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c297de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Линейная регрессия с обязательным свободным коэффициентом\n",
    "class LinReg:\n",
    "    def __init__(self):\n",
    "        self.A = None\n",
    "    \n",
    "    def _X1(self, data):\n",
    "        return np.append(data, np.ones(shape=(data.shape[0], 1)), axis=1)\n",
    "    \n",
    "    def fit(self, X, y):        \n",
    "        self.A, *_ = np.linalg.lstsq(self._X1(X), y, rcond=None)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return self._X1(data) @ self.A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e444f8b",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba1e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'train.csv'\n",
    "TEST_PATH = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5be9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    target = 'mean_exam_points'\n",
    "    subjects = ['physics', 'chemistry', 'biology', 'english', 'geography', 'history']\n",
    "    use_features = ['age', 'years_of_experience', 'qualification', 'lesson_price']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.subjects_encoder = None\n",
    "    \n",
    "    def split(self, df):\n",
    "        y_df = df[self.target]\n",
    "        X_df = df.drop(columns=[self.target], inplace=False)\n",
    "        return train_test_split(X_df, y_df, test_size = 0.3, random_state = 2021)\n",
    "    \n",
    "    def fit(self, df, y):\n",
    "        # школьные предметы заменим одной фичей через target encoding\n",
    "        self.subjects_encoder = LinReg().fit(df[self.subjects].values, y.values)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, df):\n",
    "        # Scale\n",
    "        result_df = df.drop(columns=['Id'], inplace=False).copy()\n",
    "        # Add subject feature\n",
    "        subject_feature = self.subjects_encoder.predict(df[self.subjects].values)\n",
    "        return np.hstack([result_df[self.use_features].values, subject_feature[:, np.newaxis]])\n",
    "    \n",
    "    def fit_transform(self, df, test_df=None):\n",
    "        if test_df is None:  # split df\n",
    "            train_df, test_df, y_train, y_test = self.split(df)\n",
    "        else:  # работаем с предоставленными тестовыми данными без y\n",
    "            y_train = df[self.target]\n",
    "            y_test = None\n",
    "            train_df = df.drop(columns=[self.target], inplace=False)\n",
    "        y_test_values = y_test.values if y_test is not None else None\n",
    "        self.fit(train_df, y_train)\n",
    "        X_train, X_test = self.transform(train_df), self.transform(test_df)\n",
    "        return X_train, X_test, y_train.values, y_test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46645f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция моделирования и вывода результатов на training set\n",
    "def predict_show(model):\n",
    "    raw_train_df = pd.read_csv(TRAIN_PATH)\n",
    "    X_train, X_test, y_train, y_test = Transformer().fit_transform(raw_train_df)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_score = quality_score(y_train, train_pred)\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_score = quality_score(y_test, test_pred)\n",
    "    return f\"TrainR2={train_score:.3f}, TestR2={test_score:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a15bd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция моделирования и сохранения результатов для соревнования\n",
    "def predict_save(model, outfile):\n",
    "    raw_train_df = pd.read_csv(TRAIN_PATH)\n",
    "    raw_test_df = pd.read_csv(TEST_PATH)\n",
    "    X_train, X_test, y_train, y_test = Transformer().fit_transform(raw_train_df, raw_test_df)\n",
    "    prediction = model.fit(X_train, y_train).predict(X_test)\n",
    "    prediction = np.array(prediction + 0.5, dtype=int)  # предсказываем целые баллы\n",
    "    result_df = pd.DataFrame({'Id': raw_test_df['Id'], 'mean_exam_points': prediction})\n",
    "    result_df.to_csv(outfile, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde15323",
   "metadata": {},
   "source": [
    "## Базовая метрика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76d92d",
   "metadata": {},
   "source": [
    "Сравнивать качество моделей будем с результатами линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9230b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TrainR2=0.651, TestR2=0.644'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_show(LinReg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59aff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_save(LinReg(), 'submission_linreg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500e56b",
   "metadata": {},
   "source": [
    "## Рабочая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f78266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegTree:    \n",
    "    def __init__(self, min_samples_leaf=100, min_samples_predict=20):\n",
    "        self.kwargs = {k:v for k, v in locals().items() if k != 'self'}\n",
    "        self.msl = min_samples_leaf\n",
    "        self.msp = min_samples_predict\n",
    "        self.split_feature = None  # splitting feature index\n",
    "        self.t = None  # splitting threshold\n",
    "        self.reg, self.right, self.left = LinReg(), None, None\n",
    "    \n",
    "    def fit_only(self, X, y):        \n",
    "        self.reg.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.fit_only(X, y)\n",
    "        self.split(X, y)\n",
    "        return self\n",
    "    \n",
    "    def split(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        y_pred = self.reg.predict(X)\n",
    "        best_score = quality_score(y, y_pred)\n",
    "        rmod, lmod = LinRegTree(**self.kwargs), LinRegTree(**self.kwargs)\n",
    "        for index in range(n_features):\n",
    "            for t in np.unique(X[:, index]):                \n",
    "                rmask = X[:, index] > t\n",
    "                lmask = ~rmask\n",
    "                if self.msl <= np.sum(rmask) <= n_samples - self.msl:\n",
    "                    y_pred_r = rmod.fit_only(X[rmask], y[rmask]).predict(X[rmask])\n",
    "                    y_pred_l = lmod.fit_only(X[lmask], y[lmask]).predict(X[lmask])\n",
    "                    split_score = quality_score(np.append(y[rmask], y[lmask]),\n",
    "                                                np.append(y_pred_r, y_pred_l))\n",
    "                    if split_score > best_score:\n",
    "                        best_score, self.split_feature, self.t = split_score, index, t\n",
    "                        self.right, self.left = rmod, lmod\n",
    "                        X_right, X_left = X[rmask], X[lmask]\n",
    "                        y_right, y_left = y[rmask], y[lmask]\n",
    "                        rmod, lmod = LinRegTree(**self.kwargs), LinRegTree(**self.kwargs)\n",
    "        if not (self.right is None or self.left is None):\n",
    "            self.right.split(X_right, y_right)\n",
    "            self.left.split(X_left, y_left)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "        n_samples, _ = data.shape\n",
    "        y_pred = np.zeros(n_samples)\n",
    "        split_predict = False\n",
    "        if self.split_feature:            \n",
    "            rmask = data[:, self.split_feature] > self.t\n",
    "            if self.msp <= np.sum(rmask) <= n_samples - self.msp:\n",
    "                split_predict = True\n",
    "                lmask = ~rmask                \n",
    "                y_pred[rmask] = self.right.predict(data[rmask])\n",
    "                y_pred[lmask] = self.left.predict(data[lmask])\n",
    "        return y_pred if split_predict else self.reg.predict(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d7d86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TrainR2=0.805, TestR2=0.779'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrt_model = LinRegTree(min_samples_leaf=40, min_samples_predict=40)\n",
    "predict_show(lrt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161dd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_save(lrt_model, 'submission_linregtree.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab881481",
   "metadata": {},
   "source": [
    "Получился довольно высокий результат, который говорит о том, что данные неплохо приближаются кусочной линейной регрессией. Дальнейшее улучшение результата возможно, но нужно понимать, что за каждым улучшением качества предсказания во втором-третьем знаке будет стоять существенное увеличение сложности модели и потребность в вычислительных ресурсах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4253f",
   "metadata": {},
   "source": [
    "## Потенциально улучшенная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3487da",
   "metadata": {},
   "source": [
    "Традиционно за моделью решающего дерева необходимо опробовать лес. Будем строить модели на основе бутстрап-выборок и отбирать лучшие по оценке качества на Out-of-bag данных. Эта же оценка будет использоваться в качестве веса модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c70677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegRF:\n",
    "    def __init__(self, min_samples_leaf=100, min_samples_predict=20, n_estimators=10, n_estimators_keep=5, rng=None):\n",
    "        self.msl = min_samples_leaf\n",
    "        self.msp = min_samples_predict\n",
    "        self.n_estimators = n_estimators\n",
    "        self.n_estimators_keep = n_estimators_keep\n",
    "        if rng is None or isinstance(rng, int):\n",
    "            rng = np.random.default_rng(rng)\n",
    "        self.rng = rng\n",
    "        self.estimators = []\n",
    "        self.oob_scores = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, _ = X.shape\n",
    "        for _ in range(self.n_estimators):\n",
    "            bootstrap_idx = self.rng.integers(0, n_samples, size = n_samples)\n",
    "            oob_idx = np.setdiff1d(np.arange(n_samples), bootstrap_idx)            \n",
    "            estimator = LinRegTree(min_samples_leaf=self.msl, min_samples_predict=self.msp)\n",
    "            estimator.fit(X[bootstrap_idx], y[bootstrap_idx])\n",
    "            oob_pred = estimator.predict(X[oob_idx])\n",
    "            oob_score = quality_score(y[oob_idx], oob_pred)\n",
    "            self.estimators.append(estimator)\n",
    "            self.oob_scores.append(oob_score)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "        oob_scores_all = np.array(self.oob_scores)\n",
    "        keep_idx = np.argsort(-oob_scores_all)[:self.n_estimators_keep]  # Top N\n",
    "        oob_scores = oob_scores_all[keep_idx]\n",
    "        weighted_scores = oob_scores / np.sum(oob_scores)\n",
    "        predictions = [self.estimators[i].predict(data) for i in keep_idx]\n",
    "        return weighted_scores @ np.vstack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b56bdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TrainR2=0.797, TestR2=0.780'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(2021)\n",
    "lrrf_model = LinRegRF(min_samples_leaf=120, min_samples_predict=40, n_estimators=17, n_estimators_keep=7)\n",
    "predict_show(lrrf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d0418d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_save(lrrf_model, 'submission_linregrandomforest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8bd4d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TrainR2=0.798, TestR2=0.783'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Длинные вычисления\n",
    "long_model = LinRegRF(min_samples_leaf=100, min_samples_predict=40, n_estimators=470, n_estimators_keep=47, rng=rng)\n",
    "predict_show(long_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5670e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_save(long_model, 'submission_linregrandomforest_long.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5bf8c",
   "metadata": {},
   "source": [
    "## Результаты Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f117c72",
   "metadata": {},
   "source": [
    "- результат линейной (базовой) модели: 0.65821\n",
    "- результат работы модели LinRegTree: 0.78157\n",
    "- лучший результат работы модели на основе бутстрап-выборок: 0.78656 (типичным следует назвать 0.785)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2788f0",
   "metadata": {},
   "source": [
    "**Вывод**: модель дерева решений с встроенными в листья линейными регрессорами обладает приемлемой скоростью работы и дает высокий результат при работе на данных, хорошо отвечающих на кусочно-линейную аппроксимацию. Ансамблевые модели дают незначительное улучшение качества модели при значительном потреблении вычислительных ресурсов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
